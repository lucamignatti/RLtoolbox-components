{
  "packages": {
    "rltoolbox_components": {
      "version": "0.1.0",
      "components": [
        "networks.MLPAC.MLPAC",
        "environments.gymnasium.GymnasiumEnvironment",
        "algorithms.ppo.PPO",
        "loggers.console.ConsoleLogger"
      ]
    }
  },
  "components": {
    "actor_critic": {
      "package": "rltoolbox_components",
      "type": "networks.MLPAC.MLPAC",
      "input_dim": 8,
      "output_dim": 4,
      "hidden_dims": [128, 128]
    },
    "env": {
      "package": "rltoolbox_components",
      "type": "environments.gymnasium.GymnasiumEnvironment",
      "env_name": "LunarLander-v3"
    },
    "ppo": {
      "package": "rltoolbox_components",
      "type": "algorithms.ppo.PPO",
      "actor_critic": "actor_critic",
      "learning_rate": 0.0001,
      "gamma": 0.99,
      "gae_lambda": 0.95,
      "clip_ratio": 0.2,
      "value_loss_coef": 0.5,
      "entropy_coef": 0.01,
      "num_epochs": 10,
      "batch_size": 64,
      "update_frequency": 2048
    },
    "logger": {
      "package": "rltoolbox_components",
      "type": "loggers.console.ConsoleLogger"
    }
  },
  "hooks": {
    "training_start": [],
    "episode_reset": ["env"],
    "environment_step": ["env"],
    "action_selection": ["actor_critic"],
    "experience_storage": ["ppo"],
    "episode_end": ["ppo", "logger"]
  },
  "training": {
    "max_episodes": 10000,
    "max_steps_per_episode": 500
  },
  "evaluation": {
    "enabled": true,
    "num_episodes": 10
  },
  "seed": 42
}
